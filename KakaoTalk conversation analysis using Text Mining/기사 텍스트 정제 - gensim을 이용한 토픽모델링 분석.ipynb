{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim으로 네이버 기사 토픽 모델링 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 토픽 모델링을 적용하기 위해 텍스트를 처리합니다.\n",
    "\n",
    "> 토픽 모델링 라이브러리인 gensim을 사용해봅니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 토픽 모델링\n",
    "\n",
    "   *토픽(Topic)은 한국어로는 주제라고 합니다. 토픽 모델링(Topic Modeling)이란 기계 학습 및 자연어 처리 분야에서 토픽이라는 문서 집합의 추상적인 주제를 발견하기 위한 통계적 모델 중 하나로, 텍스트 본문의 숨겨진 의미 구조를 발견하기 위해 사용되는 텍스트 마이닝 기법입니다.\n",
    " 1. 문서에서 토픽(키워드)을 찾는 과정\n",
    " 2. 문장을 구성하는 단어 조합으로부터 k개의 단어 묶음을 찾는 과정 \n",
    " 3. 베이지안 확률 모델이며 , 토픽 모델링의 결과로 각 단어가 각 토픽에 \n",
    "    속할 확률이 나옴\n",
    " 4. 잠재 디리클레 할당 (LDA)\n",
    "    * 각 문서에 여러 개의 토픽이 포함될 수있다 \n",
    "    * 각 토픽에는 여러개의 단어가 포함 될 수 있다 \n",
    "    * 문서에 존재하는 모든 단어는 반드시 어떤 토픽에 포함된다 \n",
    "    * 사람이 글을 쓰는 과정을 생성 모델로 정의한다.\n",
    "    *토픽 모델링은 문서의 집합에서 토픽을 찾아내는 프로세스를 말합니다. 이는 검색 엔진, 고객 민원 시스템 등과 같이 문서의 주제를 알아내는 일이 중요한 곳에서 사용됩니다. 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA)은 토픽 모델링의 대표적인 알고리즘입니다. 줄여서 LDA라고 합니다.\n",
    "    \n",
    "    ** LDA 모델 과정 \n",
    "       1. 문서들에 사용할 토픽을 고른다 (K개의 토픽)\n",
    "       2. 토픽 중 하나의 토픽을 고른다 \n",
    "       3. 그 토픽에 포함된 단어 중에 하나를 고른다 \n",
    "       4. 단어를 문서에 추가한다 (글을 쓴다)\n",
    "       5. B번 과정부터 반복한다. \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gensim 설치 \n",
    "    \n",
    "자연어를 벡터로 변환하는데 필요한 대부분의 편의기능을 제공하고 있는 라이브러리\n",
    "Word2vec도 포함(Word2vec : word를 vector로 바꿔주는 테크닉)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 토픽 모델링을 위한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyCom\\anaconda3\\envs\\text_analysis\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook # 진행상황을 progress bar 형태로 한눈에 확인할 수 있다\n",
    "from konlpy.tag import Mecab #Mecab, Okt 등 형태소 분석기 불러오기\n",
    "import numpy as np\n",
    "import string # 특수문자\n",
    "import re\n",
    "import warnings # 경고 알림 제거\n",
    "import pickle ## 리스트나 클래스 같은 텍스트가 아닌 자료형을 파일로 저장하기 위해 pickle 모듈 사용함 \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#gensim 라이브러리 불러오기 \n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # 경고 알림이 뜨면 모두 무시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t[스포츠경향]  안양대학교 대학일자리센터가 디지털 기초 이해도 확보 및 최신 트렌드에 맞는  IT 역량 강화를 위한 ‘코딩학개론’ 프로그램을 진행한다고  16 일 밝혔다.  10 월  11 일까지 3개월간 진행되는 이번 프로그램은 ‘코드잇’과 연계한 것으로,   IT  실무에서 많이 쓰이는 파이썬 기초, 머신 러닝, 웹퍼블리싱 등으로 교육과정을 구성하고, 학생들이 원하는 과목을 신청하여 자유롭게 수강하도록 개설된 것이 특징이다. 코드잇은 국내에서 유일하게 외주 제작 없이 대기업·아이비리그 출신 개발자들이 콘텐츠를 직접 기획, 제작해 유기적으로 연결된 강의를 제작하는 기업. 최근 글로벌 서비스를 개시해 국내뿐만 아니라 해외에도 높은 수준의 코딩 강의를 제공하고 있으며 높은 고객만족도와 향후 성장 가능성을 인정받아  2021 년 중소벤처기업부의 ‘아기 유니콘 기업’으로 선정되기도 했다.  이번 프로그램은 전공자, 비전공자 관계없이 코딩에 관심 있는 재학생 누구나 신청할 수 있으며 수강률  80 %이상, 기말평가  60 점 이상 달성 시 수료증이 발급된다. 김현태 대학일자리센터 팀장은 “4차 산업시대에 빠르게 변하는 트렌드에 맞춰 전공자들의 실질적인  IT 역량 강화와 비전공자들의 디지털 기초 이해도 확보가 기대된다”고 말했다. 앞서 안양대는 지난해 ‘대학일자리센터’ 개소식을 갖고 폭넓은 진로탐색지원, 맞춤형 진로 선택 지원, 구직활동 지원, 취업경쟁력 강화를 목표로 재학생 뿐만 아니라 지역 청년들의 진로와 취·창업을 위해 다양한 프로그램 운영에 박차를 가하고 있다.    // 본문 내용   ',\n",
       "  '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}   \\t \\t안양대학교 대학일자리센터는 최근 디지털 기초 이해도 확보와 최신 트렌드에 맞는  IT 역량 강화를 위해 \\'코딩학개론\\' 프로그램을 실시한다고  16 일 밝혔다.  이번 교육은 \\'코드잇\\'과 연계해 오는  10 월  11 일까지 3개월간  IT  실무에서 많이 쓰이는 파이썬 기초, 머신 러닝, 웹퍼블리싱 등으로 교육과정을 구성하고 학생들이 원하는 과목을 신청해 자유롭게 수강하도록 개설됐다. \\'코드잇\\'은 국내에서 유일하게 외주 제작 없이 대기업·아이비리그 출신 개발자들이 콘텐츠를 직접 기획·제작해 유기적으로 연결된 강의를 제작하는 기업이다.  최근 글로벌 서비스를 개시해 국내뿐만 아니라 해외에도 높은 수준의 코딩 강의를 제공하고 있다. 높은 고객만족도와 향후 성장 가능성을 인정받아 올해 중소벤처기업부의 \\'아기 유니콘 기업\\'으로도 선정됐다. 이번 프로그램은 (비)전공자 관계없이 코딩에 관심 있는 재학생 누구나 신청할 수 있다. 수강률  80 %이상, 기말평가  60 점 이상 달성 시 수료증이 발급된다. 김현태 대학일자리센터 팀장은 \"이번 교육을 통해 4차 산업시대에 빠르게 변하는 트렌드에 맞춰 전공자들의 실질적인  IT 역량 강화와 비전공자들의 디지털 기초 이해도 확보가 기대된다\"고 말했다. 한편 안양대는 지난해 \\'대학일자리센터\\' 개소식을 갖고 폭넓은 진로탐색지원, 맞춤형 진로 선택 지원, 구직활동 지원, 취업경쟁력 강화를 목표로 재학생 뿐만 아니라 지역 청년의 진로와 취·창업을 위한 다양한 프로그램을 운영하고 있다. article_split    // 본문 내용   ',\n",
       "  '   본문 내용     TV플레이어     // TV플레이어     // flash 오류를 우회하기 위한 함수 추가 function _flash_removeCallback() {}    [디지털데일리 이종현기자] 안랩은 지난  15 일 디지털 직무 교육 사회공헌 프로그램 ‘안랩샘’의  12 기 수료식을 온라인으로 실시한다고  16 일 밝혔다.     안랩샘  12 기에서는 ▲파이썬·인공지능( AI ) 교육 강사 ▲아두이노 ·AI  교육 강사 ▲증강현실/가상현실( AR / VR ) 실감 콘텐츠 기획자 과정 ▲프로젝트 매니저 과정 ▲소셜벤처 창업 과정 ▲소셜미디어 마케터 과정 ▲웹퍼블리셔 과정 ▲ PBL ( Problem / Project   Based   Learning ) 퍼실리테이터 과정 ▲ PR/ 커뮤니케이터 과정 등 9개 교육과정에서  110 명의 수료생을 배출했다.      안랩은 안랩샘  12 기 수료생 중 희망자를 선발해 온라인 러닝코스 개설 지원, 자체 교육 프로그램(안랩샘, 맘잡고 등) 강사/보조강사 우대 채용, 공부방 창업자 교육용품 지원 등 수료 이후 경력개발을 위한 후속 지원 프로그램을 이어 나갈 예정이다.     안랩샘  12 기 파이썬 ·AI  교육 강사 과정을 수료한 김미영 수료생은 “오랜 경력단절로 사회 재진출을 주저하다가 안랩샘을 알게 돼 교육에 성실히 참여했다”며 “안랩샘의 직무 교육으로 이번에 소프트웨어( SW ) 교육강사로 채용돼 경력을 이어갈 수 있게 됐다”고 말했다.     강석균 안랩 대표는 인사말에서 ”일상 생활이 디지털로 재편되고 있는 만큼 안랩샘 교육과정에서 배운 디지털 역량으로 안랩샘 수료생 모두가 ‘디지털 트랜스포메이션’ 시대에 활약하길 기대한다”고 말했다. \\t  // 본문 내용   ']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pickle 파일 읽기\n",
    "%time new_df = pd.read_pickle(\"naver_news_content.pk\") #pickle 파일 읽기 \n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 전처리 함수 만들기\n",
    "         -stopwords-ko.txt 텍스트파일 ANSI 형식으로 인코딩 해주기\n",
    "         - 참고 자료 : https://m.blog.naver.com/tipsware/221727268968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541f7333f1114368808d1dbd4f6b2332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_documents(input_file_name):\n",
    "    \"\"\"문서들을 주어진 이름의 파일로부터 읽어들여 돌려준다.\"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    with open(input_file_name, 'rb') as f:\n",
    "        temp_corpus = pickle.load(f)\n",
    "        \n",
    "    for page in temp_corpus:\n",
    "        corpus += page\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def text_cleaning(docs):\n",
    "    # 한국어를 제외한 글자를 제거하는 함수.\n",
    "    for doc in docs:\n",
    "        doc = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "def define_stopwords(path):\n",
    "    \n",
    "    SW = set()\n",
    "    # 불용어를 추가하는 방법 1.\n",
    "    for i in string.punctuation:\n",
    "        SW.add(i)\n",
    "\n",
    "    # 불용어를 추가하는 방법 2.\n",
    "    # stopwords-ko.txt에 직접 추가\n",
    "    \n",
    "    with open(path) as f:\n",
    "        for word in f:\n",
    "            SW.add(word)\n",
    "\n",
    "    return SW\n",
    "\n",
    "\n",
    "def text_tokenizing(corpus, tokenizer):\n",
    "    \n",
    "    mecab = Mecab(dicpath='C:\\mecab\\mecab-ko-dic')\n",
    "    token_corpus = []\n",
    "    \n",
    "\n",
    "    if tokenizer == \"noun\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = mecab.nouns(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "                \n",
    "            token_corpus.append(token_text)\n",
    "            \n",
    "    elif tokenized == \"morph\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = mecab.morphs(corpus[n])\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "\n",
    "    elif tokenizer == \"word\":\n",
    "        for n in tqdm_notebook(range(len(corpus)), desc=\"Preprocessing\"):\n",
    "            token_text = corpus[n].split()\n",
    "            token_text = [word for word in token_text if word not in SW and len(word) > 1]\n",
    "            token_corpus.append(token_text)\n",
    "        \n",
    "\n",
    "    return token_corpus\n",
    "\n",
    "\n",
    "input_file_name = \"naver_news_content.pk\"\n",
    "documents = read_documents(input_file_name)\n",
    "SW = define_stopwords(\"stopwords-ko.txt\")\n",
    "cleaned_text = text_cleaning(documents)\n",
    "tokenized_text = text_tokenizing(cleaned_text, tokenizer=\"noun\") #tokenizer= \"noun\" or \"word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 읽기의 과정은 앞서 단어 임베딩의 경우와 다르지 않다. 다음 과정은 문서-단어 행렬을 만드는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['본문', '내용', '플레이어', '플레이어', '오류', '우회', '함수', '추가', '스포츠', '경향', '안양', '대학교', '대학', '일자리', '센터', '디지털', '기초', '이해', '확보', '최신', '트렌드', '역량', '강화', '코딩', '학개', '프로그램', '진행', '개월', '진행', '이번', '프로그램', '코드', '연계', '실무', '파이썬', '기초', '머신', '러닝', '퍼블리싱', '교육', '과정', '구성', '학생', '과목', '신청', '자유', '수강', '개설', '특징', '코드', '국내', '유일', '외주', '제작', '기업', '아이비리그', '출신', '개발자', '콘텐츠', '기획', '제작', '유기', '연결', '강의', '제작', '기업', '최근', '글로벌', '서비스', '개시', '국내', '해외', '수준', '코딩', '강의', '제공', '고객', '만족도', '향후', '성장', '가능', '중소', '벤처', '기업', '아기', '유니콘', '기업', '선정', '이번', '프로그램', '전공', '전공', '코딩', '관심', '재학', '누구', '신청', '수강', '이상', '기말', '평가', '이상', '달성', '수료증', '발급', '김현태', '대학', '일자리', '센터', '팀장', '산업', '시대', '트렌드', '전공', '실질', '역량', '강화', '전공', '디지털', '기초', '이해', '확보', '기대', '양대', '지난해', '대학', '일자리', '센터', '개소식', '진로', '탐색', '지원', '맞춤', '진로', '선택', '지원', '구직', '활동', '지원', '취업', '경쟁력', '강화', '목표', '재학', '지역', '청년', '진로', '창업', '프로그램', '운영', '박차', '본문', '내용']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 토픽 모델링에 사용할 함수들 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서-단어 행렬 만들기\n",
    "# 어휘(vocabulary) 학습\n",
    "#from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_text)\n",
    "# 문서-단어 행렬(document-term matrix) 생성\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(171 unique tokens: ['가능', '강의', '강화', '개발자', '개설']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (2, 3), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.TF-IDF(단어 빈도-역 문서 빈도, Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "  TF-IDF(Term Frequency-Inverse Document Frequency)는 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취함)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법입니다. 사용 방법은 우선 DTM을 만든 후, TF-IDF 가중치를 부여합니다.\n",
    "\n",
    "TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰일 수 있습니다.\n",
    "\n",
    "TF-IDF는 TF와 IDF를 곱한 값을 의미하는데 이를 식으로 표현해보겠습니다. 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 표현할 때 TF, DF, IDF는 각각 다음과 같이 정의할 수 있습니다.\n",
    "\n",
    "(1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.\n",
    "생소한 글자때문에 어려워보일 수 있지만, 잘 생각해보면 TF는 이미 앞에서 구한 적이 있습니다. TF는 앞에서 배운 DTM의 예제에서 각 단어들이 가진 값들입니다. DTM이 각 문서에서의 각 단어의 등장 빈도를 나타내는 값이었기 때문입니다.\n",
    "\n",
    "(2) df(t) : 특정 단어 t가 등장한 문서의 수.\n",
    "여기서 특정 단어가 각 문서, 또는 문서들에서 몇 번 등장했는지는 관심가지지 않으며 오직 특정 단어 t가 등장한 문서의 수에만 관심을 가집니다. 앞서 배운 DTM에서 바나나는 문서2와 문서3에서 등장했습니다. 이 경우, 바나나의 df는 2입니다. 문서3에서 바나나가 두 번 등장했지만, 그것은 중요한 게 아닙니다. 심지어 바나나란 단어가 문서2에서 100번 등장했고, 문서3에서 200번 등장했다고 하더라도 바나나의 df는 2가 됩니다.\n",
    "\n",
    "(3) idf(d, t) : df(t)에 반비례하는 수.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.06084982941388938),\n",
       " (1, 0.12169965882777876),\n",
       " (2, 0.18254948824166817),\n",
       " (3, 0.06084982941388938),\n",
       " (5, 0.06084982941388938)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TFIDF 문서-단어 행렬 생성\n",
    "# TF-IDF로 corpus를 변환\n",
    "# corpus(말뭉치) = > nltk 패키지의 서브패키지에서는 다앙한 연구용 말뭉치를 제공한다 \n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpus_tfidf[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA모델 생성\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('과정', 0.036929026),\n",
       " ('안랩', 0.03349875),\n",
       " ('교육', 0.032891143),\n",
       " ('강사', 0.019402198),\n",
       " ('지원', 0.018727802),\n",
       " ('디지털', 0.018118385),\n",
       " ('프로그램', 0.015849968),\n",
       " ('경력', 0.012340712),\n",
       " ('수료생', 0.012300622),\n",
       " ('파이썬', 0.0103326235)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topic(3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 토픽 모델링을 추가하여 코드 완성하기\n",
    "\n",
    "   - LDA 모델의 주요 입력값은 dictionary와 corpus이다\n",
    "   - 빈도수 기반으로 BoW의 행렬 또는 TF-IDF 행렬로 corpus를 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building document-term matrix.\n",
      "\n",
      "Printing topic words.\n",
      "\n",
      "Topic ID: 0\n",
      "\t교육\t0.020134063437581062\n",
      "\t과정\t0.01933959499001503\n",
      "\t지원\t0.01856546476483345\n",
      "\t프로그램\t0.01719101145863533\n",
      "\t전공\t0.016903992742300034\n",
      "\t강화\t0.015583008527755737\n",
      "\t센터\t0.01377133745700121\n",
      "\t코딩\t0.013474454171955585\n",
      "\t일자리\t0.013459446839988232\n",
      "\t디지털\t0.013236879371106625\n",
      "\t기업\t0.013011089526116848\n",
      "\t대학\t0.012913161888718605\n",
      "\t기초\t0.012707662768661976\n",
      "\t내용\t0.011979364790022373\n",
      "\t진로\t0.011881052516400814\n",
      "\t제작\t0.011384266428649426\n",
      "\t플레이어\t0.011376134119927883\n",
      "\t본문\t0.011355482041835785\n",
      "\t안랩\t0.010759378783404827\n",
      "\t이번\t0.010608116164803505\n",
      "\t코드\t0.010289400815963745\n",
      "\t신청\t0.01004485972225666\n",
      "\t국내\t0.009928843937814236\n",
      "\t역량\t0.009752754122018814\n",
      "\t재학\t0.009469701908528805\n",
      "\t강의\t0.009315531700849533\n",
      "\t확보\t0.009268994443118572\n",
      "\t수강\t0.009232008829712868\n",
      "\t이해\t0.00896440725773573\n",
      "\t이상\t0.008546862751245499\n",
      "\n",
      "\n",
      "Topic ID: 1\n",
      "\t안랩\t0.03611671179533005\n",
      "\t교육\t0.035984765738248825\n",
      "\t과정\t0.028996383771300316\n",
      "\t프로그램\t0.019850241020321846\n",
      "\t디지털\t0.01963992789387703\n",
      "\t강사\t0.01785849593579769\n",
      "\t지원\t0.016276324167847633\n",
      "\t플레이어\t0.012492415495216846\n",
      "\t기업\t0.012299888767302036\n",
      "\t수료생\t0.012250230647623539\n",
      "\t본문\t0.010270711034536362\n",
      "\t제작\t0.01019159983843565\n",
      "\t이번\t0.010007740929722786\n",
      "\t진로\t0.00999428890645504\n",
      "\t내용\t0.009981066919863224\n",
      "\t경력\t0.009714951738715172\n",
      "\t센터\t0.009554658085107803\n",
      "\t역량\t0.00923772994428873\n",
      "\t코딩\t0.008980067446827888\n",
      "\t대학\t0.00897340290248394\n",
      "\t기초\t0.008057481609284878\n",
      "\t파이썬\t0.00794822908937931\n",
      "\t전공\t0.007943570613861084\n",
      "\t강화\t0.007534967735409737\n",
      "\t일자리\t0.007462440058588982\n",
      "\t코드\t0.007358819246292114\n",
      "\t직무\t0.007350211963057518\n",
      "\t개설\t0.0072939093224704266\n",
      "\t시대\t0.007264475338160992\n",
      "\t오류\t0.007243797183036804\n",
      "\n",
      "\n",
      "Topic ID: 2\n",
      "\t교육\t0.019978761672973633\n",
      "\t기업\t0.019293813034892082\n",
      "\t프로그램\t0.016017606481909752\n",
      "\t디지털\t0.015322954393923283\n",
      "\t전공\t0.014733160845935345\n",
      "\t안랩\t0.014050689525902271\n",
      "\t기초\t0.013909869827330112\n",
      "\t이번\t0.013884689658880234\n",
      "\t일자리\t0.013789125718176365\n",
      "\t지원\t0.013388378545641899\n",
      "\t과정\t0.01308402605354786\n",
      "\t제작\t0.012753716669976711\n",
      "\t본문\t0.012687018141150475\n",
      "\t대학\t0.012517648749053478\n",
      "\t진로\t0.01242670789361\n",
      "\t내용\t0.012329492717981339\n",
      "\t코딩\t0.011859092861413956\n",
      "\t강화\t0.011237404309213161\n",
      "\t재학\t0.010989995673298836\n",
      "\t센터\t0.010790950618684292\n",
      "\t역량\t0.010305172763764858\n",
      "\t트렌드\t0.010141834616661072\n",
      "\t강의\t0.009979970753192902\n",
      "\t플레이어\t0.009863385930657387\n",
      "\t이상\t0.008951065130531788\n",
      "\t수강\t0.008901397697627544\n",
      "\t파이썬\t0.008846205659210682\n",
      "\t이해\t0.008645805530250072\n",
      "\t국내\t0.008613510057330132\n",
      "\t확보\t0.008279277011752129\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토픽 개수, 키워드 개수를 정해주는 변수를 추가.\n",
    "NUM_TOPICS = 3\n",
    "\n",
    "NUM_TOPIC_WORDS = 30\n",
    "\n",
    "\n",
    "def build_doc_term_mat(documents):\n",
    "    # 문서-단어 행렬 만들어주는 함수.\n",
    "    print(\"Building document-term matrix.\")\n",
    "    dictionary = corpora.Dictionary(documents) #dictionary를 이용하여  corpus 생성함\n",
    "    corpus = [dictionary.doc2bow(document) for document in documents]\n",
    "        \n",
    "    return corpus, dictionary\n",
    "\n",
    "\n",
    "def print_topic_words(model):\n",
    "\n",
    "    # 토픽 모델링 결과를 출력해 주는 함수.\n",
    "    print(\"\\nPrinting topic words.\\n\")\n",
    "    \n",
    "    for topic_id in range(model.num_topics):\n",
    "        topic_word_probs = model.show_topic(topic_id, NUM_TOPIC_WORDS)\n",
    "        print(\"Topic ID: {}\".format(topic_id))\n",
    "        \n",
    "        for topic_word, prob in topic_word_probs:\n",
    "            print(\"\\t{}\\t{}\".format(topic_word, prob))\n",
    "            \n",
    "        print(\"\\n\")\n",
    "\n",
    "# document-term matrix를 만들고,\n",
    "corpus, dictionary = build_doc_term_mat(tokenized_text)\n",
    "# LDA를 실행.\n",
    "model = models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, alpha=\"auto\", eta=\"auto\")\n",
    "# 결과를 출력.\n",
    "print_topic_words(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. pyLDAvis를 통한 토픽 모델링 결과 시각화하기\n",
    "\n",
    "     -LDA 시각화를 위해서는 pyLDAvis의 설치가 필요합니다. 윈도우의 명령 프롬프트나 MAC/UNIX의 터미널에서 아래의 명령을 수행하여 pyLDAvis를 설치하시기 바랍니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: joblib in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: future in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.5.0)\n",
      "Requirement already satisfied: numexpr in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (52.0.0.post20210125)\n",
      "Requirement already satisfied: gensim in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (4.0.1)\n",
      "Collecting pyLDAvis\n",
      "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.17.0)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (3.0.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pyLDAvis) (1.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mycom\\anaconda3\\envs\\text_analysis\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->pyLDAvis) (1.16.0)\n",
      "Building wheels for collected packages: pyLDAvis\n",
      "  Building wheel for pyLDAvis (setup.py): started\n",
      "  Building wheel for pyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135593 sha256=262e5ce09089c4b45730aaa1d68d2998f5fc6e1fabfb7326d9e778caa1cb1e74\n",
      "  Stored in directory: c:\\users\\mycom\\appdata\\local\\pip\\cache\\wheels\\eb\\d1\\ac\\e8728b60e7d714da9ff6a52cb8659099c3be9e0dc19f522881\n",
      "Successfully built pyLDAvis\n",
      "Installing collected packages: funcy, pyLDAvis\n",
      "Successfully installed funcy-1.16 pyLDAvis-3.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el790823086663956482515321040\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el790823086663956482515321040_data = {\"mdsDat\": {\"x\": [0.015053808997266957, -0.006987892444131134, -0.008065916553135828], \"y\": [7.936214161430072e-05, -0.001702031446132472, 0.0016226693045181598], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [67.46945863336208, 27.50104844395038, 5.029492922687542]}, \"tinfo\": {\"Term\": [\"\\uad50\\uc721\", \"\\uc548\\ub7a9\", \"\\uacfc\\uc815\", \"\\ub514\\uc9c0\\ud138\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uac15\\uc0ac\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\uc9c0\\uc6d0\", \"\\uae30\\uc5c5\", \"\\uae30\\ucd08\", \"\\ub0b4\\uc6a9\", \"\\uc218\\ub8cc\\uc0dd\", \"\\ubcf8\\ubb38\", \"\\ucf54\\ub529\", \"\\uac15\\ud654\", \"\\uc9c4\\ub85c\", \"\\uc774\\ubc88\", \"\\uc5ed\\ub7c9\", \"\\uc77c\\uc790\\ub9ac\", \"\\ud30c\\uc774\\uc36c\", \"\\uc81c\\uc791\", \"\\uc7ac\\ud559\", \"\\uc6b0\\ud68c\", \"\\uacbd\\ub825\", \"\\uc804\\uacf5\", \"\\uc13c\\ud130\", \"\\uc218\\uac15\", \"\\ub300\\ud559\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\uae30\\ub300\", \"\\ub300\\ud559\", \"\\uc5f0\\uacb0\", \"\\ub9cc\\uc871\\ub3c4\", \"\\uae30\\ub9d0\", \"\\uc13c\\ud130\", \"\\uc77c\\uc790\\ub9ac\", \"\\ubaa9\\ud45c\", \"\\ubc15\\ucc28\", \"\\uc11c\\ube44\\uc2a4\", \"\\ucf54\\ub4dc\", \"\\uc218\\ub8cc\\uc99d\", \"\\uba38\\uc2e0\", \"\\uc774\\uc0c1\", \"\\uad6d\\ub0b4\", \"\\ud2b9\\uc9d5\", \"\\uc218\\uac15\", \"\\uc774\\ud574\", \"\\uac15\\ud654\", \"\\ud655\\ubcf4\", \"\\uc9c0\\ub09c\\ud574\", \"\\uac1c\\uc2dc\", \"\\uae30\\uc5c5\", \"\\uc7ac\\ud559\", \"\\uc9c4\\ub85c\", \"\\uacfc\\ubaa9\", \"\\ud559\\uac1c\", \"\\uc81c\\uacf5\", \"\\uc9c4\\ud589\", \"\\uc591\\ub300\", \"\\uc804\\uacf5\", \"\\ub9de\\ucda4\", \"\\ucd5c\\uadfc\", \"\\uc2e0\\uccad\", \"\\uc548\\uc591\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uae30\\ucd08\", \"\\uc9c0\\uc6d0\", \"\\uc774\\ubc88\", \"\\uac15\\uc758\", \"\\ucf54\\ub529\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\ubcf8\\ubb38\", \"\\uc81c\\uc791\", \"\\ub514\\uc9c0\\ud138\", \"\\uad50\\uc721\", \"\\ub0b4\\uc6a9\", \"\\uc5ed\\ub7c9\", \"\\uacfc\\uc815\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\uc548\\ub7a9\", \"\\uc628\\ub77c\\uc778\", \"\\uc218\\ub8cc\", \"\\uacfc\\uc815\", \"\\uacbd\\ub825\", \"\\ucc44\\uc6a9\", \"\\uac15\\uc0ac\", \"\\uc0ac\\ud68c\", \"\\uc218\\ub8cc\\uc0dd\", \"\\uc18c\\uc15c\", \"\\ud6c4\\uc18d\", \"\\uc9c4\\ucd9c\", \"\\uc774\\uc885\\ud604\", \"\\ubbf8\\ub514\\uc5b4\", \"\\uc2e4\\uc2dc\", \"\\ud504\\ub85c\\uc81d\\ud2b8\", \"\\ubaa8\\ub450\", \"\\uac00\\uc0c1\\ud604\\uc2e4\", \"\\ud76c\\ub9dd\", \"\\ubc30\\ucd9c\", \"\\uc774\\ud6c4\", \"\\ud65c\\uc57d\", \"\\uc778\\uc0ac\\ub9d0\", \"\\uc6a9\\ud488\", \"\\uc778\\uacf5\\uc9c0\\ub2a5\", \"\\ud37c\\ube14\\ub9ac\\uc154\", \"\\ub2c8\\ucf00\", \"\\ucc38\\uc5ec\", \"\\uc7ac\\ud3b8\", \"\\uad50\\uc721\", \"\\ub0b4\\uc6a9\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\uc81c\\uc791\", \"\\ub514\\uc9c0\\ud138\", \"\\ud30c\\uc774\\uc36c\", \"\\uc9c0\\uc6d0\", \"\\uc2dc\\ub300\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uc5ed\\ub7c9\", \"\\ubcf8\\ubb38\", \"\\ucf54\\ub529\", \"\\ucc3d\\uc5c5\", \"\\uc774\\ubc88\", \"\\ub7ec\\ub2dd\", \"\\uae30\\ucd08\", \"\\uc804\\uacf5\", \"\\uae30\\ud68d\", \"\\uae30\\uc5c5\", \"\\uac15\\uc758\", \"\\uc9c4\\ub85c\", \"\\uac15\\ud654\", \"\\uc13c\\ud130\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\uc77c\\uc790\\ub9ac\", \"\\ub300\\ud559\", \"\\uc2e0\\uccad\", \"\\uc774\\ud574\", \"\\uad50\\uc721\", \"\\uac15\\uc0ac\", \"\\uc218\\ub8cc\\uc0dd\", \"\\ub370\\uc77c\\ub9ac\", \"\\uc218\\ub8cc\", \"\\uc0dd\\ud65c\", \"\\uc548\\ub7a9\", \"\\ucc44\\uc6a9\", \"\\ucc3d\\uc5c5\\uc790\", \"\\uc608\\uc815\", \"\\uc18c\\ud504\\ud2b8\\uc6e8\\uc5b4\", \"\\ub2e8\\uc808\", \"\\uc778\\uc0ac\\ub9d0\", \"\\uc774\\ud130\", \"\\uc18c\\uc15c\", \"\\uc218\\ub8cc\\uc2dd\", \"\\ub514\\uc9c0\\ud138\", \"\\uc0ac\\ud68c\", \"\\uc9c1\\ubb34\", \"\\uac1c\\ubc1c\", \"\\ud2b8\\ub79c\\uc2a4\", \"\\uacf5\\ud5cc\", \"\\ud3ec\\uba54\\uc774\\uc158\", \"\\uae40\\ubbf8\\uc601\", \"\\uc790\\uccb4\", \"\\uacfc\\uc815\", \"\\ub9e4\\ub2c8\\uc800\", \"\\ud65c\\uc57d\", \"\\uacbd\\ub825\", \"\\uc6b0\\ud68c\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\ud30c\\uc774\\uc36c\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\uae30\\ucd08\", \"\\uc7ac\\ud559\", \"\\ub0b4\\uc6a9\", \"\\uc5ed\\ub7c9\", \"\\ubcf8\\ubb38\", \"\\ucf54\\ub529\", \"\\uae30\\uc5c5\", \"\\uc9c0\\uc6d0\", \"\\uac15\\ud654\", \"\\uc9c4\\ub85c\", \"\\uc774\\ubc88\", \"\\uc77c\\uc790\\ub9ac\", \"\\uae30\\ub300\", \"\\uae30\\ud68d\", \"\\uc81c\\uc791\", \"\\uc13c\\ud130\", \"\\uc804\\uacf5\", \"\\uc218\\uac15\", \"\\ub300\\ud559\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\uad6d\\ub0b4\"], \"Freq\": [8.0, 6.0, 7.0, 6.0, 8.0, 3.0, 4.0, 7.0, 7.0, 5.0, 4.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 6.0, 6.0, 4.0, 6.0, 3.0, 2.0, 5.130479188574008, 2.0694000957147956, 2.1073282731316434, 2.0223750745515434, 4.7702609910846885, 4.556513468072479, 1.9446015444846645, 1.3013411912528998, 1.939052077452431, 3.2839860950022177, 1.9218766703586536, 1.9279618310699151, 3.320574407663934, 3.1610284916023432, 1.239443419084667, 3.0703403019431796, 3.2950040374510743, 4.279423775705685, 3.1276086606225997, 1.847194693951308, 1.9002286484228943, 5.587182781814239, 2.8853319110736075, 4.261127797764096, 1.8488279781581487, 1.8420277651727357, 1.741929134473507, 1.7486556422862365, 1.1886197790501694, 5.155131466978082, 1.8913010743506373, 2.422425032672358, 3.0225311474218732, 2.4811674948054474, 5.7692042915794, 3.7127217980588405, 5.248044263712383, 3.7330675084453224, 2.8455095387435763, 3.5505606094821096, 2.7610932949576266, 3.4280174925856524, 3.4307398197622567, 3.8270934494606066, 4.675098084725007, 3.028248763137035, 2.781069638737277, 3.3511102084836573, 2.723306082186634, 3.6166386109157735, 0.871396239897948, 0.7599372722979828, 3.4068692430389507, 1.035352494611834, 0.7238600732391113, 1.636144410828452, 0.7279119635263963, 1.122784041812806, 0.6967707461217981, 0.5132771516810828, 0.4823786181848982, 0.48698989802243087, 0.47596434369477786, 0.748039877885609, 0.4896021341333281, 0.4633318152308175, 0.4938117775284122, 0.45996231279850325, 0.47645153920872646, 0.4733085569884075, 0.4565449475478199, 0.43995279894344247, 0.477496068113661, 0.4693823779937603, 0.47792166452306173, 0.44896517344953596, 0.45673819796065046, 0.47446857350520655, 3.2663019712733057, 1.6096258963683958, 1.4430953873744188, 1.6417134039576482, 1.8815141201620411, 1.0840569675054414, 2.1792925875302287, 0.9401533488755767, 2.2045897433888455, 1.2721230032198578, 1.4669511755905964, 1.4231471013729282, 0.8923984217521209, 1.392375078786872, 0.8382224519476419, 1.2779623812919652, 1.5220772623205778, 0.8234825315870624, 1.521714578673031, 1.0197781162842217, 1.1428804855122079, 1.1274903619006564, 1.1446052604395491, 0.9604872789697029, 1.0798619456873293, 1.0558392658777451, 0.9172829749855602, 0.9177367579115066, 0.8084647575132783, 0.32886507289353506, 0.23651549533551325, 0.09971496017559106, 0.13446809697240544, 0.09650049359082537, 0.5519746892203905, 0.13519273258783338, 0.09528783380766057, 0.09399703124504241, 0.09363904309674341, 0.09538376527223742, 0.09164985445816615, 0.09432974128529743, 0.13246271781008098, 0.09295337963879982, 0.46828417980033304, 0.12929301018935185, 0.1365928368539938, 0.08937927451686282, 0.08920873085155943, 0.08997611989517915, 0.08854532675239342, 0.08880404087637421, 0.08773968629073359, 0.5324818835767371, 0.08802298911981173, 0.08617168629331488, 0.16412175150931596, 0.1858311547544499, 0.2976437473924304, 0.19584343731270296, 0.36445086221291906, 0.25514090672628537, 0.2017663905013869, 0.23851194359602876, 0.21269198572696812, 0.23741972041854462, 0.23709908537535523, 0.2900378989379683, 0.29398487704455245, 0.24263223342520218, 0.24080519027057815, 0.22932236944511483, 0.23102162236262722, 0.15338169968587742, 0.15017424203106938, 0.2002052061921908, 0.20057982357520301, 0.20715524442539923, 0.17332652386155387, 0.1911680109834858, 0.1636088148260068, 0.16053264665053965], \"Total\": [8.0, 6.0, 7.0, 6.0, 8.0, 3.0, 4.0, 7.0, 7.0, 5.0, 4.0, 2.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 6.0, 6.0, 4.0, 6.0, 3.0, 2.0, 6.377486465435239, 2.587160495510809, 2.658242334067499, 2.5774272517578085, 6.115446075099441, 5.867397036122436, 2.505054003556868, 1.6804351748940762, 2.5076618004598474, 4.26913804600335, 2.501199982531061, 2.51418892744323, 4.338322113678906, 4.148696094075113, 1.6288539829806539, 4.0439031061656365, 4.34359911583331, 5.649546371031543, 4.132228269016084, 2.441450508198348, 2.512678233719841, 7.398935259425239, 3.821422454874482, 5.644813473546882, 2.450903785975396, 2.4460033986955674, 2.317824398701492, 2.3314121929806597, 1.5851683819190565, 6.884363973724059, 2.52793723499599, 3.2563509883695105, 4.092103327332848, 3.3512567200533714, 8.338244897181164, 5.245825086077091, 7.721321728287164, 5.35476495667731, 4.009736980089359, 5.2108067962303934, 3.885189388753336, 5.132388388594793, 5.272658429912096, 6.176891749422981, 8.749864813511591, 4.8763866031014595, 4.265884627684103, 7.290461335099345, 4.464045216953483, 6.7033350294629575, 1.746070037171859, 1.5907970630859347, 7.290461335099345, 2.2619413866099594, 1.6437376915611503, 3.7674926021393276, 1.7063167979952774, 2.7502905999433023, 1.7220418762580518, 1.285138561634564, 1.208141762585985, 1.2274144599122085, 1.2036461356099708, 1.9015011812703915, 1.2470526728194447, 1.1915927112017535, 1.2716932118466588, 1.1880566263189045, 1.2333026723331737, 1.2279398557920853, 1.1867997946280269, 1.1505798846502784, 1.2548528065173745, 1.236475347132225, 1.2680137201550155, 1.1950419739083287, 1.21775863573971, 1.269379528475544, 8.749864813511591, 4.8763866031014595, 4.464045216953483, 5.272658429912096, 6.176891749422981, 3.2950945497413455, 7.721321728287164, 2.8569215489835527, 8.338244897181164, 4.265884627684103, 5.132388388594793, 5.2108067962303934, 2.8225797247599016, 5.35476495667731, 2.777725979213481, 5.245825086077091, 6.884363973724059, 2.7871944068228656, 7.398935259425239, 4.009736980089359, 5.644813473546882, 5.649546371031543, 6.115446075099441, 3.885189388753336, 5.867397036122436, 6.377486465435239, 4.092103327332848, 4.34359911583331, 8.749864813511591, 3.7674926021393276, 2.7502905999433023, 1.1603056179297946, 1.5907970630859347, 1.1487376736585422, 6.7033350294629575, 1.6437376915611503, 1.1615870932191836, 1.1624097078348419, 1.162551630569523, 1.1868726000417902, 1.1505798846502784, 1.1856897784912728, 1.7220418762580518, 1.2107463100357811, 6.176891749422981, 1.7063167979952774, 1.803854848710526, 1.1867056159742064, 1.1972838043798637, 1.2078634315583068, 1.1933293059683745, 1.199585150900407, 1.1919674926478576, 7.290461335099345, 1.207923765453484, 1.1867997946280269, 2.2619413866099594, 2.564128110843968, 4.464045216953483, 3.2950945497413455, 8.338244897181164, 5.245825086077091, 3.821422454874482, 4.8763866031014595, 4.265884627684103, 5.132388388594793, 5.2108067962303934, 7.398935259425239, 7.721321728287164, 5.649546371031543, 5.644813473546882, 5.35476495667731, 5.867397036122436, 2.7910384476672023, 2.7871944068228656, 5.272658429912096, 6.115446075099441, 6.884363973724059, 4.0439031061656365, 6.377486465435239, 3.885189388753336, 4.148696094075113], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0716, -4.9796, -4.9614, -5.0026, -4.1444, -4.1903, -5.0418, -5.4434, -5.0446, -4.5178, -5.0535, -5.0504, -4.5067, -4.5559, -5.4922, -4.585, -4.5144, -4.253, -4.5666, -5.0932, -5.0648, -3.9863, -4.6472, -4.2573, -5.0923, -5.096, -5.1518, -5.148, -5.534, -4.0668, -5.0696, -4.8221, -4.6007, -4.7981, -3.9543, -4.3951, -4.049, -4.3896, -4.6611, -4.4397, -4.6912, -4.4748, -4.474, -4.3647, -4.1646, -4.5988, -4.684, -4.4975, -4.705, -3.5238, -4.947, -5.0839, -3.5836, -4.7746, -5.1325, -4.317, -5.1269, -4.6936, -5.1707, -5.4763, -5.5384, -5.5289, -5.5518, -5.0997, -5.5235, -5.5787, -5.515, -5.586, -5.5508, -5.5574, -5.5934, -5.6305, -5.5486, -5.5657, -5.5477, -5.6102, -5.593, -5.5549, -3.6257, -4.3334, -4.4426, -4.3136, -4.1773, -4.7287, -4.0304, -4.8711, -4.0188, -4.5687, -4.4262, -4.4565, -4.9232, -4.4784, -4.9858, -4.5641, -4.3893, -5.0036, -4.3895, -4.7898, -4.6758, -4.6894, -4.6743, -4.8497, -4.7325, -4.755, -4.8957, -4.8952, -3.3231, -4.2226, -4.5522, -5.4159, -5.1169, -5.4487, -3.7047, -5.1115, -5.4613, -5.475, -5.4788, -5.4603, -5.5002, -5.4714, -5.1319, -5.4861, -3.8691, -5.1561, -5.1012, -5.5253, -5.5272, -5.5187, -5.5347, -5.5318, -5.5438, -3.7407, -5.5406, -5.5619, -4.9176, -4.7934, -4.3223, -4.7409, -4.1198, -4.4764, -4.7111, -4.5438, -4.6584, -4.5484, -4.5497, -4.3482, -4.3347, -4.5267, -4.5342, -4.5831, -4.5757, -4.9853, -5.0064, -4.7189, -4.717, -4.6848, -4.863, -4.7651, -4.9207, -4.9397], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.1759, 0.1702, 0.1613, 0.151, 0.1451, 0.1406, 0.1402, 0.1378, 0.1363, 0.1311, 0.13, 0.128, 0.1261, 0.1216, 0.1203, 0.1181, 0.1172, 0.1157, 0.1149, 0.1146, 0.1141, 0.1126, 0.1125, 0.1123, 0.1116, 0.1099, 0.1079, 0.1059, 0.1056, 0.1042, 0.1034, 0.0977, 0.0905, 0.0929, 0.0252, 0.0478, 0.0074, 0.0327, 0.0505, 0.0099, 0.052, -0.0101, -0.0363, -0.0852, -0.2333, -0.0829, -0.0343, -0.3838, -0.1007, 0.6739, 0.5959, 0.5522, 0.5302, 0.5095, 0.4708, 0.4569, 0.439, 0.3951, 0.3861, 0.3731, 0.3728, 0.3665, 0.3632, 0.358, 0.356, 0.3463, 0.345, 0.342, 0.3399, 0.3376, 0.3356, 0.3296, 0.3247, 0.3223, 0.3152, 0.312, 0.3103, 0.3069, 0.3056, 0.1825, 0.1617, 0.1242, 0.1022, 0.1792, 0.026, 0.1795, -0.0394, 0.081, 0.0386, -0.0069, 0.1395, -0.056, 0.0928, -0.1212, -0.2182, 0.0717, -0.2906, -0.0782, -0.3062, -0.3206, -0.3848, -0.1065, -0.4016, -0.5075, -0.2045, -0.2636, 0.6082, 0.5513, 0.5364, 0.5357, 0.5192, 0.513, 0.493, 0.4918, 0.4892, 0.4749, 0.4709, 0.4687, 0.4598, 0.4586, 0.4249, 0.423, 0.4104, 0.4098, 0.4092, 0.4038, 0.393, 0.3928, 0.3889, 0.3866, 0.3809, 0.3731, 0.3708, 0.3672, 0.3665, 0.3653, 0.2819, 0.167, -0.1404, -0.0335, 0.0486, -0.0279, -0.0087, -0.0836, -0.1002, -0.2492, -0.2784, -0.1579, -0.1647, -0.1608, -0.2448, 0.0886, 0.0689, -0.2811, -0.4275, -0.5137, -0.1599, -0.5175, -0.1776, -0.2622]}, \"token.table\": {\"Topic\": [1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1], \"Freq\": [0.7863531791192578, 0.530857047699131, 0.530857047699131, 0.7481787496029586, 0.24939291653431953, 0.7080214476175094, 0.17700536190437735, 0.8426689707531775, 0.7959634358113344, 0.3979817179056672, 0.4420981047164668, 0.4420981047164668, 0.8279081673247323, 0.8160255051399546, 0.4080127525699773, 0.41149659289141816, 0.41149659289141816, 0.13716553096380604, 0.5714374000703384, 0.34286244004220306, 0.11428748001406767, 0.7231187659863534, 0.24103958866211778, 0.7165791648881205, 0.35828958244406023, 0.7759675849768398, 0.8109274901894585, 0.2703091633964862, 0.7625111272993781, 0.19062778182484452, 0.7175674560425831, 0.35878372802129155, 0.8336215226150485, 0.6152096304447954, 0.4101397536298636, 0.8367906917357446, 0.842550413553055, 0.7840079359006165, 0.1568015871801233, 0.8618419014329947, 0.6475748907812191, 0.32378744539060955, 0.720013426438235, 0.3600067132191175, 0.7523768523164357, 0.7911588833427554, 0.3955794416713777, 0.8278668146119103, 0.7954851674706374, 0.8392129211595067, 0.7983859817633657, 0.83080896487341, 0.595083949050896, 0.8108309682879309, 0.5845231835273043, 0.1948410611757681, 0.5860576425051216, 0.5860576425051216, 0.8705207663427309, 0.7975557149027217, 0.8176018459812349, 0.16352036919624696, 0.5807059710841479, 0.5807059710841479, 0.8601768503908163, 0.7418575374434605, 0.24728584581448684, 0.6286156941100539, 0.6286156941100539, 0.3635979412577766, 0.3635979412577766, 0.8259368554015639, 0.7996161898162667, 0.7000542246991586, 0.3500271123495793, 0.7331193178729778, 0.24437310595765926, 0.5259002780802381, 0.5259002780802381, 0.44753842480111683, 0.5967178997348225, 0.14917947493370562, 0.5967910449928612, 0.2983955224964306, 0.6308478086027476, 0.7032538996791068, 0.2344179665597023, 0.7730482911556362, 0.860281872441212, 0.5727147128758466, 0.5727147128758466, 0.7969062146622008, 0.7799922287586916, 0.3899961143793458, 0.7469982403265079, 0.18674956008162696, 0.691511584753211, 0.23050386158440364, 0.8147207260956707, 0.8433909258056073, 0.6906714731256814, 0.23022382437522715, 0.8143721333606749, 0.8087504553320164, 0.8691269622742905, 0.8521666369631482, 0.17043332739262965, 0.8389490537016092, 0.7877864559553326, 0.7850479855147388, 0.26168266183824623, 0.7262835055037448, 0.2905134022014979, 0.8628781374121586, 0.568972945977465, 0.37931529731830993, 0.8191851496821398, 0.6475575265413995, 0.2590230106165598, 0.554368329976685, 0.554368329976685, 0.7086150886552901, 0.17715377216382253, 0.8277174343013648, 0.8578491637049576, 0.8211807912103734, 0.7085716596260632, 0.3542858298130316, 0.860891108241082, 0.6083695744971593, 0.6083695744971593, 0.6141844067618218, 0.3070922033809109, 0.7027179650019791, 0.2342393216673264, 0.7676354461834363, 0.19190886154585907, 0.8352238594908186, 0.7721631302412848, 0.25738771008042827, 0.6139285721425388, 0.6069628563942099, 0.30348142819710494, 0.7886349998466494, 0.8379916549426483, 0.7195758908482487, 0.23985863028274956, 0.8018907475167937, 0.6720362035327612, 0.22401206784425373, 0.8176603520120139, 0.40883017600600696, 0.7260005509604444, 0.24200018365348144, 0.8426021006461544, 0.7781262113309423, 0.7781262113309423, 0.8417107213975293], \"Term\": [\"\\uac00\\uc0c1\\ud604\\uc2e4\", \"\\uac15\\uc0ac\", \"\\uac15\\uc0ac\", \"\\uac15\\uc758\", \"\\uac15\\uc758\", \"\\uac15\\ud654\", \"\\uac15\\ud654\", \"\\uac1c\\ubc1c\", \"\\uac1c\\uc2dc\", \"\\uac1c\\uc2dc\", \"\\uacbd\\ub825\", \"\\uacbd\\ub825\", \"\\uacf5\\ud5cc\", \"\\uacfc\\ubaa9\", \"\\uacfc\\ubaa9\", \"\\uacfc\\uc815\", \"\\uacfc\\uc815\", \"\\uacfc\\uc815\", \"\\uad50\\uc721\", \"\\uad50\\uc721\", \"\\uad50\\uc721\", \"\\uad6d\\ub0b4\", \"\\uad6d\\ub0b4\", \"\\uae30\\ub300\", \"\\uae30\\ub300\", \"\\uae30\\ub9d0\", \"\\uae30\\uc5c5\", \"\\uae30\\uc5c5\", \"\\uae30\\ucd08\", \"\\uae30\\ucd08\", \"\\uae30\\ud68d\", \"\\uae30\\ud68d\", \"\\uae40\\ubbf8\\uc601\", \"\\ub0b4\\uc6a9\", \"\\ub0b4\\uc6a9\", \"\\ub2c8\\ucf00\", \"\\ub2e8\\uc808\", \"\\ub300\\ud559\", \"\\ub300\\ud559\", \"\\ub370\\uc77c\\ub9ac\", \"\\ub514\\uc9c0\\ud138\", \"\\ub514\\uc9c0\\ud138\", \"\\ub7ec\\ub2dd\", \"\\ub7ec\\ub2dd\", \"\\ub9cc\\uc871\\ub3c4\", \"\\ub9de\\ucda4\", \"\\ub9de\\ucda4\", \"\\ub9e4\\ub2c8\\uc800\", \"\\uba38\\uc2e0\", \"\\ubaa8\\ub450\", \"\\ubaa9\\ud45c\", \"\\ubbf8\\ub514\\uc5b4\", \"\\ubc15\\ucc28\", \"\\ubc30\\ucd9c\", \"\\ubcf8\\ubb38\", \"\\ubcf8\\ubb38\", \"\\uc0ac\\ud68c\", \"\\uc0ac\\ud68c\", \"\\uc0dd\\ud65c\", \"\\uc11c\\ube44\\uc2a4\", \"\\uc13c\\ud130\", \"\\uc13c\\ud130\", \"\\uc18c\\uc15c\", \"\\uc18c\\uc15c\", \"\\uc18c\\ud504\\ud2b8\\uc6e8\\uc5b4\", \"\\uc218\\uac15\", \"\\uc218\\uac15\", \"\\uc218\\ub8cc\", \"\\uc218\\ub8cc\", \"\\uc218\\ub8cc\\uc0dd\", \"\\uc218\\ub8cc\\uc0dd\", \"\\uc218\\ub8cc\\uc2dd\", \"\\uc218\\ub8cc\\uc99d\", \"\\uc2dc\\ub300\", \"\\uc2dc\\ub300\", \"\\uc2e0\\uccad\", \"\\uc2e0\\uccad\", \"\\uc2e4\\uc2dc\", \"\\uc2e4\\uc2dc\", \"\\uc548\\ub7a9\", \"\\uc548\\ub7a9\", \"\\uc548\\ub7a9\", \"\\uc548\\uc591\", \"\\uc548\\uc591\", \"\\uc591\\ub300\", \"\\uc5ed\\ub7c9\", \"\\uc5ed\\ub7c9\", \"\\uc5f0\\uacb0\", \"\\uc608\\uc815\", \"\\uc628\\ub77c\\uc778\", \"\\uc628\\ub77c\\uc778\", \"\\uc6a9\\ud488\", \"\\uc6b0\\ud68c\", \"\\uc6b0\\ud68c\", \"\\uc774\\ubc88\", \"\\uc774\\ubc88\", \"\\uc774\\uc0c1\", \"\\uc774\\uc0c1\", \"\\uc774\\uc885\\ud604\", \"\\uc774\\ud130\", \"\\uc774\\ud574\", \"\\uc774\\ud574\", \"\\uc774\\ud6c4\", \"\\uc778\\uacf5\\uc9c0\\ub2a5\", \"\\uc778\\uc0ac\\ub9d0\", \"\\uc77c\\uc790\\ub9ac\", \"\\uc77c\\uc790\\ub9ac\", \"\\uc790\\uccb4\", \"\\uc7ac\\ud3b8\", \"\\uc7ac\\ud559\", \"\\uc7ac\\ud559\", \"\\uc804\\uacf5\", \"\\uc804\\uacf5\", \"\\uc81c\\uacf5\", \"\\uc81c\\uc791\", \"\\uc81c\\uc791\", \"\\uc9c0\\ub09c\\ud574\", \"\\uc9c0\\uc6d0\", \"\\uc9c0\\uc6d0\", \"\\uc9c1\\ubb34\", \"\\uc9c1\\ubb34\", \"\\uc9c4\\ub85c\", \"\\uc9c4\\ub85c\", \"\\uc9c4\\ucd9c\", \"\\uc9c4\\ud589\", \"\\ucc38\\uc5ec\", \"\\ucc3d\\uc5c5\", \"\\ucc3d\\uc5c5\", \"\\ucc3d\\uc5c5\\uc790\", \"\\ucc44\\uc6a9\", \"\\ucc44\\uc6a9\", \"\\ucd5c\\uadfc\", \"\\ucd5c\\uadfc\", \"\\ucf54\\ub4dc\", \"\\ucf54\\ub4dc\", \"\\ucf54\\ub529\", \"\\ucf54\\ub529\", \"\\ud2b8\\ub79c\\uc2a4\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\ud2b8\\ub80c\\ub4dc\", \"\\ud2b9\\uc9d5\", \"\\ud30c\\uc774\\uc36c\", \"\\ud30c\\uc774\\uc36c\", \"\\ud37c\\ube14\\ub9ac\\uc154\", \"\\ud3ec\\uba54\\uc774\\uc158\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\ud504\\ub85c\\uadf8\\ub7a8\", \"\\ud504\\ub85c\\uc81d\\ud2b8\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\ud50c\\ub808\\uc774\\uc5b4\", \"\\ud559\\uac1c\", \"\\ud559\\uac1c\", \"\\ud655\\ubcf4\", \"\\ud655\\ubcf4\", \"\\ud65c\\uc57d\", \"\\ud6c4\\uc18d\", \"\\ud6c4\\uc18d\", \"\\ud76c\\ub9dd\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el790823086663956482515321040\", ldavis_el790823086663956482515321040_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el790823086663956482515321040\", ldavis_el790823086663956482515321040_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.2.2/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el790823086663956482515321040\", ldavis_el790823086663956482515321040_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.015054  0.000079       1        1  67.469459\n",
       "0     -0.006988 -0.001702       2        1  27.501048\n",
       "2     -0.008066  0.001623       3        1   5.029493, topic_info=     Term      Freq     Total Category  logprob  loglift\n",
       "14     교육  8.000000  8.000000  Default  30.0000  30.0000\n",
       "142    안랩  6.000000  6.000000  Default  29.0000  29.0000\n",
       "12     과정  7.000000  7.000000  Default  28.0000  28.0000\n",
       "30    디지털  6.000000  6.000000  Default  27.0000  27.0000\n",
       "100  프로그램  8.000000  8.000000  Default  26.0000  26.0000\n",
       "..    ...       ...       ...      ...      ...      ...\n",
       "74     전공  0.207155  6.884364   Topic3  -4.6848  -0.5137\n",
       "46     수강  0.173327  4.043903   Topic3  -4.8630  -0.1599\n",
       "28     대학  0.191168  6.377486   Topic3  -4.7651  -0.5175\n",
       "94    트렌드  0.163609  3.885189   Topic3  -4.9207  -0.1776\n",
       "17     국내  0.160533  4.148696   Topic3  -4.9397  -0.2622\n",
       "\n",
       "[190 rows x 6 columns], token_table=      Topic      Freq  Term\n",
       "term                       \n",
       "112       1  0.786353  가상현실\n",
       "113       1  0.530857    강사\n",
       "113       2  0.530857    강사\n",
       "1         1  0.748179    강의\n",
       "1         2  0.249393    강의\n",
       "...     ...       ...   ...\n",
       "107       2  0.242000    확보\n",
       "168       1  0.842602    활약\n",
       "169       1  0.778126    후속\n",
       "169       2  0.778126    후속\n",
       "170       1  0.841711    희망\n",
       "\n",
       "[158 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyLDAvis 불러오기\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# pyLDAvis를 jupyter notebook에서 실행할 수 있게 활성화.\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# pyLDAvis 실행.\n",
    "data = pyLDAvis.gensim.prepare(model, corpus, dictionary)\n",
    "data\n",
    "\n",
    "# pyLDAvis 실행결과 깃허브에서 안보여집니다.\n",
    "# 밑에 링크를 통해 실행결과 확인 가능합니다\n",
    "#https://nbviewer.jupyter.org/github/SEONGJAE-YOO/MachineLearning-dataAnalysis/blob/main/KakaoTalk%20conversation%20analysis%20using%20Text%20Mining/%EA%B8%B0%EC%82%AC%20%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%A0%95%EC%A0%9C%20-%20gensim%EC%9D%84%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%ED%86%A0%ED%94%BD%EB%AA%A8%EB%8D%B8%EB%A7%81%20%EB%B6%84%EC%84%9D.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:text_analysis]",
   "language": "python",
   "name": "conda-env-text_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_metadata": {
   "author": "이기황",
   "coursetitle": "텍스트분석기법",
   "courseyear": "2018",
   "date": "2018.04.18",
   "logofile": "figs/ewhauniv-logo.png",
   "logoraise": "-.2",
   "logoscale": ".4",
   "title": "단어 임베딩과 토픽 모델링"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
